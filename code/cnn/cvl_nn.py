"""
Function：Convolution Neural Network
Author：lzb
Date：2021.01.10
"""

import numpy as np
import operator

from nn.neural_network import NeuralNetwork
from gl import errorcode
from gl.common_enum import ArrayDim
from gl.common_function import rand_array_3

from cnn.convolution import Convolution, ConvolutionType, Reversal, cal_cvl_wh

"""
class：CVLNeuralNetwork，卷积神经网络
说明：
1、继承自 NeuralNetwork
2、重载 _modify_wb 函数

特别说明：
1、每一层的 w，还是一个 matrix，不过它的定义是：卷积核
2、每一层的神经元个数，将由上一层的神经元个数和卷积参数确定（w，s，padding），而不是由外部输入
3、卷积参数：步长 s = 1，补零 padding = 0
4、激活函数是 ReLU 函数
5、输入样本 sx，为了计算方便，将是1个3维矩阵，为了方便理解，可以这么认为：
A. 第1维：图像像素的 x 坐标
B. 第2维：图像像素的 y 坐标
C. 第3维：图像像素的颜色值。如果是 RGB 图像，则第3维有3个值（r, g, b），如果是灰度图像，则第3维只有1个值（gray）
6、从这个意义上讲，参数 sx_dim 将变为1个”3元祖“：sx_dim[0] 表示图像的宽度，sx_dim[1] 表示图像的高度，sx_dim[2] 表示图像的颜色深度
7、输出样本，暂时还定义为分类，所以它还是一个1维向量。因此，sy_dim 还是表示1维向量的元素个数（1维向量的维度）
"""


class CVLNeuralNetwork(NeuralNetwork):
    # 可以理解为图像宽度
    width = 1

    # 可以理解为图像高度
    height = 1

    # 可以理解为颜色深度（颜色维度）
    depth = 1

    # 卷积对象
    cvl = None

    # 每一层神经网络的输出（经过激活函数以后的输出），a 是一个三维数组
    a_list = None

    # 卷积步长
    s = 1

    # 卷积两端补齐长度
    padding = 0

    # 卷积类型
    cvl_type = ConvolutionType.Narrow

    # 是否翻转卷积
    rev = Reversal.NO_REV

    """
    功能：构造函数
    参数：
    cvl：卷积对象
    返回值：NULL
    """

    def __init__(self, cvl):
        self.cvl = cvl

    """
    功能：参数校验
    参数：NULL    
    返回值：错误码    
    """

    def _valid(self):
        # 调用父类的 _valid
        err = super()._valid()

        if errorcode.SUCCESS != err:
            return err

        # 校验 w_shape_list

        if self.w_shape_list is None:
            return errorcode.FAILED

        if 0 >= len(self.w_shape_list):
            return errorcode

        # 这里只处理3维数组
        shape = self.w_shape_list[0]

        if 3 != len(shape):
            return errorcode.FAILED

        if (0 >= shape[0]) or (0 >= shape[1]) or (0 >= shape[1]):
            return errorcode.FAILED

        return errorcode.SUCCESS

    """
    功能：校验每层神经元
    参数：NULL    
    返回值：错误码
    说明：对于卷积神经网络来说，这里不需要校验
    """

    def _valid_layer_neuron(self):
        return errorcode.SUCCESS

    """
    功能：校验样本
    参数：NULL    
    返回值：错误码
    说明：理解卷积神经网络，理解卷积对图像的处理，恐怕是从样本的校验开始
    """

    def _valid_sample(self):
        # 1 输入样本的数量与输出样本的数量，须相同（equal with parent class）
        len1 = len(self.sx_list)
        len2 = len(self.sy_list)

        if len1 != len2:
            return errorcode.FAILED

        # 2 样本数量，须 >= 1（same as parent class）
        sample_count = len(self.sx_list)
        if 1 > sample_count:
            return errorcode.FAILED

        # 3. 样本数组维度（different with parent class）

        # 3.1 输入数组维度
        sx_dim = self.sx_list[0].shape

        # 输入样本必须是3维样本：图像的宽度、高度，颜色的深度
        if ArrayDim.THREE.value != len(sx_dim):
            return errorcode.FAILED

        width = sx_dim[0]
        height = sx_dim[1]
        depth = sx_dim[2]

        # 图像宽度/高度须大于0
        if (0 > width) or (0 > height):
            return errorcode.FAILED

        # 颜色深度须介于1~3之间
        if (3 < depth) or (1 > depth):
            return errorcode.FAILED

        # 3.2 每一个输入/输出样本的维度
        for i in range(0, sample_count):
            shape_in = self.sx_list[i].shape
            shape_out = self.sy_list[i].shape

            # 输入样本的维度须相等(都是3维)
            if not operator.eq(sx_dim, shape_in):
                return errorcode.FAILED

            # 输入样本的宽度、高度、深度
            if (shape_in[0] != width) or (shape_in[1] != height) or (shape_in[2] != depth):
                return errorcode.FAILED

            """
            # 输出样本的向量维度
            if shape_out[0] != sy_dim:
                return errorcode.FAILED

            # 输出样本只能有1列（因为是个向量）
            if shape_out[1] != 1:
                return errorcode.FAILED
            """

        return errorcode.SUCCESS

    """
    功能：初始化其它参数
    参数：NULL   
    返回值：错误码
    """

    def _init_other_para(self):
        # 样本数量
        self.sample_count = len(self.sx_list)

        # 神经网络输入，维度(3维)
        self.sx_dim = self.sx_list[0].shape

        # 图像宽度，高度，深度
        self.width = self.sx_dim[0]
        self.height = self.sx_dim[1]
        self.depth = self.sx_dim[2]

        # 神经网络输出，向量维度
        # self.sy_dim = self.neuron_count_list[self.layer_count - 1]

        # 初始化 self.layer_count
        self.layer_count = len(self.w_shape_list)

        # 初始化 W, B
        self._init_w_b()

        return errorcode.SUCCESS

    """
    功能：初始化 W, B
    参数：NULL
    返回值：NULL
    
    特别说明，这里就假设 w 是 3维数组
    """

    def _init_w_b(self):
        # 每一层 w、B 参数，w 是个 matrix，b 是个 vector（数据类型也是一个 matrix）
        self.W = list()
        self.B = list()

        # 第1层

        w0 = np.asarray([[[12071.309562], [15377.210377], [4448.563263]],
                        [[14387.443066], [15075.763724], [7188.361990]],
                        [[19705.518657], [17181.649717], [13014.594954]]])

        b0 = np.asarray([[[0.623123], [1.779860], [2.095327], [2.114642], [3.055280], [-4.579717], [-66.549237], [22.034244], [-17.353663], [7.825338], [-18.203573], [1.050627], [2.293353], [2.330696], [2.168613], [2.864549], [1.745849], [0.653354]],
                        [[1.380302], [2.080475], [3.311091], [20.540202], [-19.073015], [-24.771445], [-59.161407], [-51.851169], [-78.262277], [-57.488496], [-37.178790], [15.149654], [12.003292], [0.600718], [2.509341], [2.934833], [2.039899], [0.872826]],
                        [[0.442040], [2.477051], [4.611809], [-4.619813], [-20.294800], [-76.137611], [-73.835443], [76.208022], [112.093414], [32.624095], [-104.304554], [-138.869678], [30.941529], [-7.780527], [4.580397], [5.073021], [3.892096], [1.946854]],
                        [[0.361482], [2.663736], [4.478000], [4.276762], [-6.284491], [-45.494664], [13.809831], [-74.853218], [-9.963969], [-39.317466], [-31.818377], [15.364583], [96.957026], [-16.627513], [4.978710], [4.715217], [4.130899], [2.085967]],
                        [[0.821018], [2.344130], [4.969612], [-20.773538], [22.112559], [-50.522208], [107.338870], [36.774786], [6.362571], [34.647473], [-30.381541], [-97.761572], [-45.659370], [47.909021], [4.955663], [5.053029], [3.883078], [1.828972]],
                        [[0.954014], [2.026667], [4.142501], [-10.748189], [13.552926], [-21.794572], [14.629246], [-164.900257], [37.377112], [176.966195], [-105.495322], [-66.749194], [-20.506163], [75.515788], [4.979714], [4.765948], [4.190724], [2.667707]],
                        [[0.853238], [2.888861], [4.379182], [-10.535381], [-3.095937], [11.437516], [-71.961938], [0.279247], [138.296674], [-199.890954], [-24.576330], [-19.628473], [0.609008], [17.603795], [4.528715], [4.984607], [4.088705], [1.665648]],
                        [[0.671099], [2.985815], [-20.649433], [2.576357], [-125.833173], [25.131473], [-102.622601], [242.862220], [-227.063488], [-76.445604], [101.451002], [-32.126754], [-8.055189], [16.915917], [4.195560], [4.880097], [4.053223], [2.578404]],
                        [[0.351232], [2.562896], [-10.945905], [-57.711895], [-41.606405], [56.666399], [-37.017636], [-99.047889], [-103.348158], [219.099346], [-63.931683], [-3.463501], [-43.519241], [18.974805], [3.789599], [4.142094], [3.875218], [2.114524]],
                        [[1.036842], [2.928597], [14.587629], [-62.388102], [42.579012], [-82.263265], [55.207855], [-62.622106], [213.341377], [-206.537785], [17.624379], [30.991743], [24.879163], [24.834252], [4.490072], [4.825459], [3.406500], [2.045372]],
                        [[1.169902], [2.985835], [20.883634], [-58.378390], [-46.414827], [-22.774029], [25.937416], [-23.910274], [68.685295], [15.346277], [118.716383], [-101.069078], [41.646998], [-8.230029], [4.635741], [3.903578], [3.463806], [1.761815]],
                        [[0.867692], [2.636253], [65.053528], [-108.595754], [-85.163704], [15.620268], [23.637945], [44.305692], [-34.396641], [70.031903], [-47.970952], [-25.512849], [61.215358], [10.997118], [4.286290], [4.578584], [4.257442], [1.793005]],
                        [[0.399390], [2.948524], [-10.003763], [3.433096], [-94.434110], [122.482799], [-75.267799], [3.165624], [32.450196], [54.469986], [-83.553593], [19.564142], [-18.566821], [10.983770], [4.464219], [4.707444], [3.766746], [2.556300]],
                        [[0.823575], [2.381168], [-6.084789], [33.383596], [-250.056051], [7.188154], [-48.857677], [182.583608], [-99.358521], [-37.436399], [35.783366], [-0.895572], [-31.671321], [10.008538], [3.838383], [4.653049], [3.995176], [2.202395]],
                        [[0.597646], [2.266538], [4.875688], [7.595060], [14.247710], [-37.036203], [6.780482], [-110.557529], [3.347089], [64.685001], [-56.011946], [-35.740931], [-24.273948], [14.008485], [4.515336], [4.751082], [3.797960], [1.726472]],
                        [[0.600293], [2.451602], [4.216384], [1.731963], [20.010711], [-105.022961], [104.921414], [-16.612096], [59.515298], [-113.133131], [-9.135382], [55.264364], [3.993352], [19.659266], [4.291544], [4.329468], [4.300370], [2.254264]],
                        [[0.121554], [0.507390], [1.444962], [2.537911], [-8.540469], [-5.493313], [40.144670], [-75.125057], [51.399933], [21.032764], [2.193447], [2.229158], [2.051877], [1.955090], [2.293493], [2.568163], [1.483517], [0.696749]],
                        [[-0.235660], [0.639563], [2.158261], [1.454444], [2.557903], [19.850694], [-6.613873], [-42.251849], [24.137572], [1.940871], [1.348749], [1.044056], [0.675514], [1.654553], [2.046332], [1.443651], [1.595236], [0.691386]]])

        self.W.append(w0)
        self.B.append(b0)

        # 第2层

        w1 = np.asarray([[[0.815742], [0.345272], [-0.046124]],
                        [[0.083514], [0.123640], [0.332807]],
                        [[0.553320], [0.752220], [0.248960]]])

        b1 = np.asarray([[[1.960071], [1.963842], [1.973021], [1.962191], [1.958408], [-1.765839], [-2.362734], [-1.765839], [-1.765839], [-0.982527], [1.956804], [1.955206], [1.981640], [1.963067], [1.967239], [1.968507]],
                        [[1.955801], [1.954084], [1.978622], [-1.002731], [-1.775833], [-2.835838], [-2.394335], [-2.407831], [-3.274184], [-3.275609], [-2.407831], [-0.982975], [1.964450], [1.964220], [1.974867], [1.957338]],
                        [[1.968904], [1.964170], [1.961169], [1.957588], [-0.878103], [-1.844203], [-2.882499], [-1.243092], [-1.994848], [-2.853356], [-1.879667], [-1.871769], [1.960236], [1.981886], [1.958353], [1.959637]],
                        [[1.977455], [1.964069], [1.958123], [1.966956], [-1.052857], [-2.422674], [-2.470462], [-1.052857], [-3.274875], [-3.273243], [-0.982975], [-1.871769], [1.956957], [1.964427], [1.967001], [1.956174]],
                        [[1.963075], [1.957600], [1.959624], [-1.052857], [-1.881647], [-2.422674], [-1.961420], [-3.690640], [-3.725512], [-2.450005], [1.978210], [-1.116003], [1.963386], [1.966524], [1.955194], [1.967533]],
                        [[1.971566], [1.968249], [1.965733], [-1.052857], [-1.907548], [-0.982975], [-3.278017], [-4.194309], [-2.345980], [-1.928203], [1.954988], [-1.116003], [1.955410], [1.966320], [1.954291], [1.955132]],
                        [[1.964755], [1.959569], [1.961904], [-1.052857], [-1.907548], [-1.849345], [-2.873784], [-2.851841], [-1.243092], [-1.243092], [-1.871023], [-1.116003], [1.961373], [1.982403], [1.955355], [1.974956]],
                        [[1.953882], [1.982899], [-1.052857], [-1.116003], [-2.875296], [-3.283056], [-3.689431], [-3.271696], [-2.445948], [-2.445948], [-2.417310], [-1.052857], [1.975503], [1.968346], [1.977218], [1.957030]],
                        [[1.966132], [1.971776], [-1.052857], [-1.899626], [-2.857965], [-2.351839], [-2.403599], [-2.422994], [-1.045195], [-1.928945], [-2.402566], [1.967728], [1.959536], [1.983101], [1.979872], [1.970586]],
                        [[1.957053], [1.954790], [1.956099], [-1.871769], [-2.392945], [-0.878103], [-1.164739], [-1.881647], [-2.461998], [-2.469379], [-2.402566], [-0.982975], [1.965865], [1.960569], [1.956094], [1.965832]],
                        [[1.966466], [1.963112], [-0.982527], [-2.407831], [-2.366946], [1.955182], [-1.920332], [-1.052857], [-2.461998], [-1.116003], [-0.982527], [-0.982975], [1.966899], [1.976956], [1.968829], [1.965388]],
                        [[1.957483], [1.959979], [-1.852106], [-3.275609], [-1.795862], [-1.045195], [-1.920332], [-2.889680], [-2.889680], [1.958661], [-0.982527], [-0.982975], [1.966133], [1.975417], [1.961265], [1.971209]],
                        [[1.963183], [1.963322], [-1.072101], [-3.715627], [-2.402566], [-2.872095], [-2.879149], [-2.889680], [-0.982527], [-1.812839], [-1.812839], [-0.982975], [1.968352], [1.970468], [1.966488], [1.957676]],
                        [[1.972503], [1.956811], [1.972990], [-1.808511], [-2.849610], [-3.695824], [-3.271298], [-2.407593], [-2.345980], [-1.766575], [-0.878103], [-0.878103], [1.982165], [1.978929], [1.957694], [1.971174]],
                        [[1.971333], [1.968902], [1.956638], [1.966910], [1.963551], [-1.164739], [-1.844203], [-0.982975], [1.958243], [1.956557], [1.981657], [1.974861], [1.979158], [1.954923], [1.960275], [1.972717]],
                        [[1.968253], [1.953843], [1.980798], [1.970895], [-1.164739], [-1.164739], [-1.052857], [1.960951], [1.955286], [1.972073], [1.972553], [1.980573], [1.954884], [1.958573], [1.969145], [1.959591]]])

        self.W.append(w1)
        self.B.append(b1)

        """
        # 1. W，B 是 list
        self.W = list()
        self.B = list()

        # 2. 针对每一层进行初始化
        b = 0
        for layer in range(0, self.layer_count):
            # 2.1 每一层的卷积核
            width = self.w_shape_list[layer][0]
            height = self.w_shape_list[layer][1]

            # 如果是第一层，depth = 输入层的 depth
            if 0 == layer:
                depth = self.w_shape_list[layer][2]
            # 否则的话，depth = 1
            else:
                depth = 1

            w = rand_array_3(width, height, depth)
            # w = np.zeros([width, height, depth])
            self.W.append(w)

            # 2.2 每一层的 b

            # 如果是第一层，x 就是样本输入
            if 0 == layer:
                x = self.sx_list[0]
            # 否则的话，x 是上一层的输出
            # 上一层的输出的 width，height 等同于 b
            else:
                x = b

            width, height = cal_cvl_wh(w, x, self.s)

            # 每一层的b，都是 [width, height, depth] 3维数组
            depth = 1  # b 的 depth = 1
            b = rand_array_3(width, height, depth)
            # b = np.zeros([width, height, depth])

            self.B.append(b)
        """

    """
    功能：计算某一层神经网络的输出
    参数：
    x：该层神经网络的输入，x 是一个3维数组
    w: 该层神经网络的 w 参数, w 是一个3维数组
    b：该层神经网络的 b 参数，b 是一个2维数组
    返回值：y，该层神经网络的输出（sigmoid(cvl(w, x) + b)）， y 是一个3维数字
    """

    def _calc_layer(self, x, layer):
        # 1、获取该层的参数：w, b
        w = self.W[layer]
        b = self.B[layer]

        # 2、计算卷积结果
        y, err = self.cvl.convolution_sum_depth(w, x)
        # y, err = cvl.convolution(w, x)

        # 3. y = y + b
        y_width = y.shape[0]
        y_height = y.shape[1]
        y_depth = y.shape[2]

        for i in range(0, y_width):
            for j in range(0, y_height):
                for k in range(0, y_depth):
                    y[i, j, k] += b[i, j, k]

        # 针对每一个元素，调用激活函数
        for i in range(0, y_width):
            for j in range(0, y_height):
                for k in range(0, y_depth):
                    y[i, j, k] = self.activation.active(y[i, j, k])

        return y

    """
    功能：修正 W，B
    参数：
    nn_y_list：神经网路计算的每一层结果，nn_y 是一个向量
    sx：训练样本的输入，sx 是一个向量
    sy：训练样本的输出，sy 是一个向量 
    返回值：NULL
    """

    def _modify_wb(self, nn_y_list, sx, sy):
        # 1. 后向传播，计算 ksi_list
        ksi_list = self.__bp(nn_y_list, sy)

        # 2. 通过 ksi_list，修正 W，B
        self.__modify_wb_by_ksi_list(ksi_list, sx, nn_y_list)

    """
    功能：后向传播，计算 ksi_list
    参数：
    nn_y_list：神经网路计算的每一层结果，nn_y 是一个3维数组    
    sy：训练样本的输出，sy 是一个3维数组
    返回值：ksi_list
    说明：
    1、ksi(代表希腊字母，音：科赛)，是一个3维数组，每层都有，代表目标函数 E 对每一层中间输出的偏导
    2、ksi_list 记录每一层的 ksi
    """

    def __bp(self, nn_y_list, sy):
        # 1. 初始化 ksi_list
        ksi_list = [0] * self.layer_count

        # 2. 计算最后一层 ksi

        # 2.1 计算误差(err)：最后一层的计算结果与样本输出结果的比较（计算结果 - 训练样本的输出）
        nn_y_last = nn_y_list[self.layer_count - 1]
        err = np.subtract(nn_y_last, sy)  # 不知道3维数组是否可以这样相减

        # 2.2 计算最后一层 ksi

        # 最后一层 ksi：ksi_last，ksi_last 是个[width, height, 1] 3维数组
        width = nn_y_last.shape[0]
        height = nn_y_last.shape[1]
        depth = nn_y_last.shape[2]  # 实际的值，depth = 1

        ksi_last = np.zeros([width, height, depth])

        # 计算 ksi_last 每一个元素
        for k in range(0, depth):
            for i in range(0, width):
                for j in range(0, height):
                    ksi_last[i, j, k] = err[i, j, k] * self.activation.derivative(nn_y_last[i, j, k])

        # 将 ksi_last 放置入 ksi_list
        ksi_list[self.layer_count - 1] = ksi_last

        # 3. 反向传播，计算：倒数第2层 ~ 第1层的 ksi
        for layer in range(self.layer_count - 2, -1, -1):
            # 下一层的 ksi
            ksi_next = ksi_list[layer + 1]

            # 下一层的 w
            w = self.W[layer + 1]

            # 当前层的 ksi
            ksi_cur, err = self.cvl.convolution(w, ksi_next, Reversal.REV, ConvolutionType.Wide)

            # 将当前层计算出的 ksi 放置到 ksiList
            ksi_list[layer] = ksi_cur

        # return 计算结果
        return ksi_list

    """
    功能：修正 W，B
    参数： 
    ksi_list：每一层的 ksi 的列表，ksi 是一个3维数组
    sx：输入样本，sx 是一个3维数组
    nn_y_list：神经网络的每一层的计算结果列表，nn_y 是一个3维数组    
    返回值：NULL  
    """

    def __modify_wb_by_ksi_list(self, ksi_list, sx, nn_y_list):
        # 逐层修正
        for layer in range(0, self.layer_count):
            # 当前层 w, b, ksi
            w = self.W[layer]
            b = self.B[layer]
            ksi = ksi_list[layer]

            # 上一层的输入
            if 0 == layer:
                v = sx
            else:
                v = nn_y_list[layer - 1]

            # 损失函数针对当前层的 w 的偏导(partial derivative)，w_pd 是1个3维数组
            w_pd, err = self.cvl.convolution(ksi, v)

            # 修正当前层的 w
            self.W[layer] = np.subtract(w, self.rate * w_pd)  # 不知道3维数组是否可以这样相减

            # 损失函数针对当前层的 b 的偏导(partial derivative)，b_pd 等于 ksi
            b_pd = ksi

            # 修正当前层的 b
            self.B[layer] = np.subtract(b, self.rate * b_pd)  # 不知道3维数组是否可以这样相减

    """
    功能：预测
    参数：
    sx_list：待预测的样本列表，其中 sx 是向量 
    返回值：预测结果
    """

    def predict(self, sx_list, sy_list):
        count = len(sx_list)
        py_list = list()

        for i in range(0, count):
            sx = sx_list[i]
            nn_y_list = self._calc_nn(sx)

            # 最后一层的 nn_y，才是神经网络的最终输出
            nn_y = nn_y_list[len(nn_y_list) - 1]

            # 然后再添加到预测列表
            py_list.append(nn_y)

        return py_list
